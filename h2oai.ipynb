{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook demonstrates how to:\n",
    "- Upload documents into a collection and ingest them\n",
    "- Create and upload prompt template\n",
    "- Get two collections to chat to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2ogpte import H2OGPTE\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from random import sample as rsamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_API_KEY = \"USE_YOUR_h2ogpte_GLOBAL_KEY_HERE\"\n",
    "general_client = H2OGPTE(\n",
    "    address='https://h2ogpte.genai.h2o.ai',\n",
    "    api_key=GLOBAL_API_KEY,\n",
    ")\n",
    "\n",
    "collection_ids = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_collection(client, files, c_name, c_description, \n",
    "                      collection_id = None, ingest=True, save_id=False):\n",
    "    '''\n",
    "    This function uploads and ingests files into a collection given Path(s)\n",
    "        files: Path/List[Path]\n",
    "        Either a path or a list of paths to the document(s)\n",
    "    '''\n",
    "    if collection_id is None:\n",
    "        collection_id = client.create_collection(\n",
    "            name = c_name,\n",
    "            description = c_description\n",
    "        )\n",
    "\n",
    "    uploads = []\n",
    "    if isinstance(files, Path): # Single File\n",
    "        with open(files, 'rb') as f:\n",
    "            upload_id = client.upload(files.name, f)\n",
    "            uploads.append(upload_id)\n",
    "    \n",
    "    elif isinstance(files, list): # Multiple files\n",
    "        for fi in files:\n",
    "            with open(fi, 'rb') as f:\n",
    "                upload_id = client.upload(fi.name, f)\n",
    "                uploads.append(upload_id)\n",
    "    \n",
    "    else: \n",
    "        raise Exception(\"Invalid file type (Path/List[Path]) provided to files parameter.\")\n",
    "\n",
    "    if ingest:\n",
    "        client.ingest_uploads(collection_id, uploads)\n",
    "\n",
    "    if save_id is not False:\n",
    "        save_id[collection_id] = {\"name\":c_name, \"description:\":c_description}\n",
    "    \n",
    "    return collection_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMEDIAN_PATH = Path(\"./data/comedian/stand_up_transcripts.txt\")\n",
    "EDUCATOR_PATH = Path(\"./data/educator/ted_transcripts.txt\")\n",
    "LAWYER_PATH = Path(\"./data/lawyer/court_transcripts.txt\")\n",
    "PHILOSOPHER_PATH = Path(\"./data/philosopher/all_philo.txt\")\n",
    "POLITICIAN_PATH = Path(\"./data/politician/un_transcripts.txt\")\n",
    "RAPPER_PATH = Path(\"./data/rapper/Eminem/ALL_eminem.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "educator_collection_id = upload_collection(general_client, Path(\"./data/comedian/stand_up_split/output_2.txt\"), \n",
    "                                         c_name=\"Test\",\n",
    "                                         c_description=\"test desc\",\n",
    "                                         ingest=True,\n",
    "                                         save_id=collection_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f2383730-cac3-469f-8443-73ec2fbf4b7e'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "educator_collection_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "educator_collection_id = upload_collection(general_client, EDUCATOR_PATH, \n",
    "                                         c_name=\"Educator Personality\",\n",
    "                                         c_description=\"Contains transcripts of various ted talks.\",\n",
    "                                         ingest=True,\n",
    "                                         save_id=collection_ids)\n",
    "\n",
    "comedian_collection_id = upload_collection(general_client, COMEDIAN_PATH, \n",
    "                                         c_name=\"Comedian Personality\",\n",
    "                                         c_description=\"Contains stand-up transcripts from https://scrapsfromtheloft.com/stand-up-comedy-scripts/\",\n",
    "                                         ingest=True,\n",
    "                                         save_id=collection_ids)\n",
    "\n",
    "lawyer_collection_id = upload_collection(general_client, LAWYER_PATH, \n",
    "                                         c_name=\"Lawyer Personality\",\n",
    "                                         c_description=\"Contains transcripts of supreme court cases.\",\n",
    "                                         ingest=True,\n",
    "                                         save_id=collection_ids)\n",
    "\n",
    "philosopher_collection_id = upload_collection(general_client, PHILOSOPHER_PATH, \n",
    "                                         c_name=\"Philosopher Personality\",\n",
    "                                         c_description=\"Contains works by Aristotle, Plato, Epictetus, Aeschylus\",\n",
    "                                         ingest=True,\n",
    "                                         save_id=collection_ids)\n",
    "\n",
    "politician_collection_id = upload_collection(general_client, POLITICIAN_PATH, \n",
    "                                         c_name=\"Politician Personality\",\n",
    "                                         c_description=\"Contains transcripts of some UN general debates.\",\n",
    "                                         ingest=True,\n",
    "                                         save_id=collection_ids)\n",
    "\n",
    "rapper_collection_id = upload_collection(general_client, RAPPER_PATH, \n",
    "                                         c_name=\"Rapper Personality\",\n",
    "                                         c_description=\"Contains lyrics to songs by Eminem\",\n",
    "                                         ingest=True,\n",
    "                                         save_id=collection_ids)\n",
    "\n",
    "with open(\"collection_ids.json\", \"w\") as file:\n",
    "    json.dump(collection_ids, file, indent=4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files were too big and got stuck even after waiting for the whole day\n",
    "Here I tried breaking it down into smaller chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems to take forever to upload files, breaking big txt into smaller txts\n",
    "def split_file(input_file, output_dir, max_chars=10000, clear=True):\n",
    "    \"\"\"\n",
    "    Splits a text file into multiple text files, each containing a maximum\n",
    "    number of characters.\n",
    "\n",
    "    Args:\n",
    "        input_file (str): The path to the input text file.\n",
    "        output_dir (str): The directory path to save the output files.\n",
    "        max_chars (int): The maximum number of characters per output file.\n",
    "            Default is 10,000.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    if clear and os.listdir(output_dir): \n",
    "        print(f\"Clearing directory: {output_dir}\")\n",
    "        for filename in os.listdir(output_dir):\n",
    "            file_path = os.path.join(output_dir, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "\n",
    "    with open(input_file, 'r', encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    chunks = [content[i:i+max_chars] for i in range(0, len(content), max_chars)]\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        output_file = os.path.join(output_dir, f'output_{i+1}.txt')\n",
    "        with open(output_file, 'w', encoding=\"utf-8\") as f:\n",
    "            f.write(chunk)\n",
    "\n",
    "    print(f\"Input file '{input_file}' split into {len(chunks)} output files in '{output_dir}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing directory: ./data/comedian/stand_up_split/\n",
      "Input file './data/comedian/stand_up_transcripts.txt' split into 141 output files in './data/comedian/stand_up_split/'.\n"
     ]
    }
   ],
   "source": [
    "split_file(input_file=\"./data/comedian/stand_up_transcripts.txt\", output_dir=\"./data/comedian/stand_up_split/\", max_chars=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file './data/educator/ted_transcripts.txt' split into 282 output files in './data/educator/ted_transcripts_split/'.\n",
      "Input file './data/lawyer/court_transcripts.txt' split into 49 output files in './data/lawyer/court_transcripts_split/'.\n",
      "Input file './data/philosopher/all_philo.txt' split into 103 output files in './data/philosopher/philo_transcripts_split/'.\n",
      "Input file './data/politician/un_transcripts.txt' split into 1349 output files in './data/politician/un_transcripts_split/'.\n",
      "Input file './data/rapper/Eminem/ALL_eminem.txt' split into 10 output files in './data/rapper/eminem_lyrics_split/'.\n"
     ]
    }
   ],
   "source": [
    "split_file(input_file=\"./data/educator/ted_transcripts.txt\", output_dir=\"./data/educator/ted_transcripts_split/\", max_chars=100000)\n",
    "split_file(input_file=\"./data/lawyer/court_transcripts.txt\", output_dir=\"./data/lawyer/court_transcripts_split/\", max_chars=100000)\n",
    "split_file(input_file=\"./data/philosopher/all_philo.txt\", output_dir=\"./data/philosopher/philo_transcripts_split/\", max_chars=100000)\n",
    "split_file(input_file=\"./data/politician/un_transcripts.txt\", output_dir=\"./data/politician/un_transcripts_split/\", max_chars=100000)\n",
    "split_file(input_file=\"./data/rapper/Eminem/ALL_eminem.txt\", output_dir=\"./data/rapper/eminem_lyrics_split/\", max_chars=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_directory(out_dir, c_name, c_description, client, choose_random=15):\n",
    "    '''\n",
    "    This function uploads and ingests all .txt files in directory specified by out_dir.\n",
    "    out_dir: str\n",
    "    c_name: str (Name of collection)\n",
    "    c_description: str (Description of collection)\n",
    "    client: h2ogpte client initialised with GLOBAL key\n",
    "    choose_random: int (if specified, choose n out of all the files available in out_dir)\n",
    "    '''\n",
    "    c_id = None\n",
    "    out_files = os.listdir(out_dir)\n",
    "    choose_random = min(choose_random,len(out_files))\n",
    "    random_indices = rsamp(range(len(out_files)), choose_random)\n",
    "    print(f\"Random chosen files: {random_indices}\")\n",
    "    for i, ri in enumerate(random_indices):\n",
    "        out_file = out_files[ri]\n",
    "        start_time = time.time()\n",
    "        out_dir_ = out_dir + out_file \n",
    "        out_path = Path(out_dir_)\n",
    "        f_id = upload_collection(client, out_path, \n",
    "                                c_name=c_name,\n",
    "                                c_description=c_description,\n",
    "                                collection_id=c_id,\n",
    "                                ingest=True)\n",
    "        if c_id is None:\n",
    "            c_id = f_id\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"{i+1}/{len(random_indices)} {out_file} Done. Time taken: {end_time-start_time:.2f}s\")\n",
    "    return c_id\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading and ingesting smaller chunks works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random chosen files: [62, 29, 7, 73, 3, 57, 17, 104, 18, 115, 44, 71, 56, 65, 78]\n",
      "1/141 output_28.txt Done. Time taken: 29.45s\n",
      "2/141 output_125.txt Done. Time taken: 27.68s\n",
      "3/141 output_105.txt Done. Time taken: 28.33s\n",
      "4/141 output_38.txt Done. Time taken: 25.70s\n",
      "5/141 output_101.txt Done. Time taken: 27.10s\n",
      "6/141 output_23.txt Done. Time taken: 26.22s\n",
      "7/141 output_114.txt Done. Time taken: 24.41s\n",
      "8/141 output_66.txt Done. Time taken: 29.06s\n",
      "9/141 output_115.txt Done. Time taken: 28.08s\n",
      "10/141 output_76.txt Done. Time taken: 35.23s\n",
      "11/141 output_139.txt Done. Time taken: 26.53s\n",
      "12/141 output_36.txt Done. Time taken: 29.29s\n",
      "13/141 output_22.txt Done. Time taken: 26.48s\n",
      "14/141 output_30.txt Done. Time taken: 28.40s\n",
      "15/141 output_42.txt Done. Time taken: 25.94s\n"
     ]
    }
   ],
   "source": [
    "comedian_collection_id = ingest_directory(client=general_client,\n",
    "                                          out_dir = \"./data/comedian/stand_up_split/\",\n",
    "                                          c_name = \"Comedian Personality\",\n",
    "                                          c_description=\"Contains stand-up transcripts from https://scrapsfromtheloft.com/stand-up-comedy-scripts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random chosen files: [81, 42, 273, 9, 35, 110, 153, 30, 57, 270, 189, 225, 198, 169, 274]\n",
      "1/15 output_172.txt Done. Time taken: 33.49s\n",
      "2/15 output_137.txt Done. Time taken: 26.97s\n",
      "3/15 output_91.txt Done. Time taken: 25.80s\n",
      "4/15 output_107.txt Done. Time taken: 26.86s\n",
      "5/15 output_130.txt Done. Time taken: 24.60s\n",
      "6/15 output_199.txt Done. Time taken: 29.01s\n",
      "7/15 output_237.txt Done. Time taken: 29.53s\n",
      "8/15 output_126.txt Done. Time taken: 27.47s\n",
      "9/15 output_150.txt Done. Time taken: 25.36s\n",
      "10/15 output_89.txt Done. Time taken: 26.07s\n",
      "11/15 output_27.txt Done. Time taken: 26.89s\n",
      "12/15 output_48.txt Done. Time taken: 28.77s\n",
      "13/15 output_278.txt Done. Time taken: 25.79s\n",
      "14/15 output_251.txt Done. Time taken: 31.18s\n",
      "15/15 output_92.txt Done. Time taken: 25.89s\n"
     ]
    }
   ],
   "source": [
    "educator_collection_id = ingest_directory(client=general_client,\n",
    "                                          out_dir = \"./data/educator/ted_transcripts_split/\",\n",
    "                                          c_name = \"Educator Personality\",\n",
    "                                          c_description=\"Contains transcripts of ted talks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random chosen files: [39, 41, 28, 35, 22, 2, 8, 11, 32, 26, 17, 37, 18, 25, 12]\n",
      "1/15 output_45.txt Done. Time taken: 28.93s\n",
      "2/15 output_47.txt Done. Time taken: 26.50s\n",
      "3/15 output_35.txt Done. Time taken: 25.04s\n",
      "4/15 output_41.txt Done. Time taken: 25.55s\n",
      "5/15 output_3.txt Done. Time taken: 25.77s\n",
      "6/15 output_11.txt Done. Time taken: 26.20s\n",
      "7/15 output_17.txt Done. Time taken: 26.09s\n",
      "8/15 output_2.txt Done. Time taken: 26.10s\n",
      "9/15 output_39.txt Done. Time taken: 26.22s\n",
      "10/15 output_33.txt Done. Time taken: 25.70s\n",
      "11/15 output_25.txt Done. Time taken: 25.89s\n",
      "12/15 output_43.txt Done. Time taken: 25.35s\n",
      "13/15 output_26.txt Done. Time taken: 27.60s\n",
      "14/15 output_32.txt Done. Time taken: 26.64s\n",
      "15/15 output_20.txt Done. Time taken: 26.93s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0b0605cf-7ddd-401b-af00-6bb770eb4900'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lawyer_collection_id = ingest_directory(client=general_client,\n",
    "                                          out_dir = \"./data/lawyer/court_transcripts_split/\",\n",
    "                                          c_name = \"Lawyer Personality\",\n",
    "                                          c_description=\"Contains transcripts of supreme court cases.\")\n",
    "lawyer_collection_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random chosen files: [100, 60, 31, 23, 12, 52, 53, 83, 39, 41, 69, 57, 86, 95, 59]\n",
      "1/15 output_97.txt Done. Time taken: 38.89s\n",
      "2/15 output_60.txt Done. Time taken: 35.35s\n",
      "3/15 output_34.txt Done. Time taken: 39.34s\n",
      "4/15 output_27.txt Done. Time taken: 35.19s\n",
      "5/15 output_17.txt Done. Time taken: 38.60s\n",
      "6/15 output_53.txt Done. Time taken: 33.54s\n",
      "7/15 output_54.txt Done. Time taken: 34.50s\n",
      "8/15 output_81.txt Done. Time taken: 34.48s\n",
      "9/15 output_41.txt Done. Time taken: 32.44s\n",
      "10/15 output_43.txt Done. Time taken: 35.57s\n",
      "11/15 output_69.txt Done. Time taken: 33.93s\n",
      "12/15 output_58.txt Done. Time taken: 34.55s\n",
      "13/15 output_84.txt Done. Time taken: 37.26s\n",
      "14/15 output_92.txt Done. Time taken: 34.27s\n",
      "15/15 output_6.txt Done. Time taken: 29.41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'44855d1f-db69-447d-83d8-d5be841745e0'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "philosopher_collection_id = ingest_directory(client=general_client,\n",
    "                                          out_dir = \"./data/philosopher/philo_transcripts_split/\",\n",
    "                                          c_name = \"Philosopher Personality\",\n",
    "                                          c_description=\"Contains works by Plato, Aristotle, Aeschylus, and Epictetus.\")\n",
    "philosopher_collection_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random chosen files: [1326, 1346, 265, 1259, 1199, 20, 863, 999, 1209, 923, 412, 1025, 142, 338, 289]\n",
      "1/15 output_979.txt Done. Time taken: 30.36s\n",
      "2/15 output_997.txt Done. Time taken: 27.57s\n",
      "3/15 output_1237.txt Done. Time taken: 31.43s\n",
      "4/15 output_918.txt Done. Time taken: 29.73s\n",
      "5/15 output_864.txt Done. Time taken: 23.62s\n",
      "6/15 output_1016.txt Done. Time taken: 29.26s\n",
      "7/15 output_561.txt Done. Time taken: 29.70s\n",
      "8/15 output_684.txt Done. Time taken: 33.46s\n",
      "9/15 output_873.txt Done. Time taken: 25.76s\n",
      "10/15 output_615.txt Done. Time taken: 24.07s\n",
      "11/15 output_155.txt Done. Time taken: 23.38s\n",
      "12/15 output_707.txt Done. Time taken: 24.90s\n",
      "13/15 output_1126.txt Done. Time taken: 23.34s\n",
      "14/15 output_1302.txt Done. Time taken: 28.70s\n",
      "15/15 output_1259.txt Done. Time taken: 23.42s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'52c3a1cd-5c69-4f36-b38f-bb2a81c3baa0'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politician_collection_id = ingest_directory(client=general_client,\n",
    "                                          out_dir = \"./data/politician/un_transcripts_split/\",\n",
    "                                          c_name = \"Politician Personality\",\n",
    "                                          c_description=\"Contains transcripts of UN General Debates.\")\n",
    "politician_collection_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random chosen files: [3, 4, 1, 7, 2, 9, 0, 8, 5, 6]\n",
      "1/10 output_3.txt Done. Time taken: 27.79s\n",
      "2/10 output_4.txt Done. Time taken: 27.59s\n",
      "3/10 output_10.txt Done. Time taken: 15.50s\n",
      "4/10 output_7.txt Done. Time taken: 26.42s\n",
      "5/10 output_2.txt Done. Time taken: 31.91s\n",
      "6/10 output_9.txt Done. Time taken: 27.25s\n",
      "7/10 output_1.txt Done. Time taken: 29.59s\n",
      "8/10 output_8.txt Done. Time taken: 29.71s\n",
      "9/10 output_5.txt Done. Time taken: 26.08s\n",
      "10/10 output_6.txt Done. Time taken: 27.33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'616a5dde-be45-49fd-a438-cfe5616e697a'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rapper_collection_id = ingest_directory(client=general_client,\n",
    "                                          out_dir = \"./data/rapper/eminem_lyrics_split/\",\n",
    "                                          c_name = \"Rapper Personality\",\n",
    "                                          c_description=\"Contains song lyrics by Eminem.\")\n",
    "rapper_collection_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise collection-specific apis\n",
    "COLLECTION_KEY_1 = \"COLLECTION_KEY_HERE\"\n",
    "COLLECTION_KEY_2 = \"COLLECTION_KEY_HERE\"\n",
    "COLLECTION_KEY_3 = \"COLLECTION_KEY_HERE\"\n",
    "COLLECTION_KEY_4 = \"COLLECTION_KEY_HERE\"\n",
    "COLLECTION_KEY_5 = \"COLLECTION_KEY_HERE\"\n",
    "COLLECTION_KEY_6 = \"COLLECTION_KEY_HERE\"\n",
    "politician_client = H2OGPTE(\n",
    "    address='https://h2ogpte.genai.h2o.ai',\n",
    "    api_key=COLLECTION_KEY_1,)\n",
    "rapper_client = H2OGPTE(\n",
    "    address='https://h2ogpte.genai.h2o.ai',\n",
    "    api_key=COLLECTION_KEY_2,)\n",
    "philosopher_client = H2OGPTE(\n",
    "    address='https://h2ogpte.genai.h2o.ai',\n",
    "    api_key=COLLECTION_KEY_3,)\n",
    "lawyer_client = H2OGPTE(\n",
    "    address='https://h2ogpte.genai.h2o.ai',\n",
    "    api_key=COLLECTION_KEY_4,)\n",
    "educator_client = H2OGPTE(\n",
    "    address='https://h2ogpte.genai.h2o.ai',\n",
    "    api_key=COLLECTION_KEY_5,)\n",
    "comedian_client = H2OGPTE(\n",
    "    address='https://h2ogpte.genai.h2o.ai',\n",
    "    api_key=COLLECTION_KEY_6,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client_dict\n",
    "all_clients = {\n",
    "    \"politician\": politician_client,\n",
    "    \"rapper\": rapper_client,\n",
    "    \"philosopher\": philosopher_client,\n",
    "    \"lawyer\": lawyer_client,\n",
    "    \"educator\": educator_client,\n",
    "    \"comedian\": comedian_client\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a prompt templates\n",
    "# System Prompts\n",
    "rapper_prompt = '''You are a skilled rapper, dropping fire lyrics and spittin' hot rhymes straight from your neural networks. \n",
    "Get ready to flow with sick beats and lyrical genius, while maintaining clarity, objectivity, and avoiding harmful or unethical content.'''\n",
    "educator_prompt = '''You are an esteemed educator, imparting knowledge through engaging discussions and thought-provoking lessons. \n",
    "Your role is to foster intellectual growth, curiosity, and critical thinking in a clear, concise, and ethical manner.'''\n",
    "politician_prompt = '''You are a passionate yet objective politician, advocating for the greater good of the nation through transparent and ethical means. \n",
    "Unite diverse voices by providing relevant context, clear communication, and a commitment to promoting positive change.'''\n",
    "comedian_prompt = '''You are a hilarious comedian tasked with bringing laughter through witty, clever, and family-friendly jokes and comedic genius. \n",
    "Prepare for a wild ride of nonstop laughter, while avoiding harmful, offensive, or unethical content.'''\n",
    "lawyer_prompt = '''You are a skilled lawyer, upholding justice and providing expert legal counsel. \n",
    "Employ sound reasoning, persuasive arguments, and clear communication to zealously represent your clients within ethical boundaries.'''\n",
    "philosopher_prompt = '''You are a deep philosopher, pondering the great questions of existence and inviting others to join you in rich, \n",
    "objective intellectual discourse on the nature of reality.'''\n",
    "\n",
    "# Common texts\n",
    "common_description = \"This template's goal is for the LLM to capture the personality and tone of the documents provided.\"\n",
    "common_pre_prompt_query = \"Familiarize yourself with the writing style and voice present in the following text. The actual information and facts are not important.\"\n",
    "common_prompt_query = \"Now respond in a way that matches the personality and tone exemplified.\"\n",
    "\n",
    "rapper_template_id = general_client.create_prompt_template(\n",
    "    name=\"Rapper Template\",\n",
    "    lang=\"English\",\n",
    "    description=common_description,\n",
    "    system_prompt=rapper_prompt,\n",
    "    pre_prompt_query=common_pre_prompt_query,\n",
    "    prompt_query=common_prompt_query\n",
    ")\n",
    "\n",
    "educator_template_id = general_client.create_prompt_template(\n",
    "    name=\"Educator Template\",\n",
    "    lang=\"English\",\n",
    "    description=common_description,\n",
    "    system_prompt=educator_prompt,\n",
    "    pre_prompt_query=common_pre_prompt_query,\n",
    "    prompt_query=common_prompt_query\n",
    ")\n",
    "\n",
    "politician_template_id = general_client.create_prompt_template(\n",
    "    name=\"Politician Template\",\n",
    "    lang=\"English\",\n",
    "    description=common_description,\n",
    "    system_prompt=politician_prompt,\n",
    "    pre_prompt_query=common_pre_prompt_query,\n",
    "    prompt_query=common_prompt_query\n",
    ")\n",
    "\n",
    "comedian_template_id = general_client.create_prompt_template(\n",
    "    name=\"Comedian Template\",\n",
    "    lang=\"English\",\n",
    "    description=common_description,\n",
    "    system_prompt=comedian_prompt,\n",
    "    pre_prompt_query=common_pre_prompt_query,\n",
    "    prompt_query=common_prompt_query\n",
    ")\n",
    "\n",
    "lawyer_template_id = general_client.create_prompt_template(\n",
    "    name=\"Lawyer Template\",\n",
    "    lang=\"English\",\n",
    "    description=common_description,\n",
    "    system_prompt=lawyer_prompt,\n",
    "    pre_prompt_query=common_pre_prompt_query,\n",
    "    prompt_query=common_prompt_query\n",
    ")\n",
    "\n",
    "philosopher_template_id = general_client.create_prompt_template(\n",
    "    name=\"Philosopher Template\",\n",
    "    lang=\"English\",\n",
    "    description=common_description,\n",
    "    system_prompt=philosopher_prompt,\n",
    "    pre_prompt_query=common_pre_prompt_query,\n",
    "    prompt_query=common_prompt_query\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once prompt template created, should be able to access through h2oai web app\n",
    "However, the templates I created stopped showing up, so here I saved the prompt_template_ids manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_template_ids = {\n",
    "    \"Comedian\": comedian_template_id,\n",
    "    \"Lawyer\": lawyer_template_id,\n",
    "    \"Philosopher\": philosopher_template_id,\n",
    "    \"Politician\": politician_template_id,\n",
    "    \"Educator\": educator_template_id,\n",
    "    \"Rapper\": rapper_template_id,\n",
    "}\n",
    "\n",
    "with open(\"prompt_template_ids.json\", \"w\") as file:\n",
    "    json.dump(all_template_ids, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_long_str(longstr, tok_per_line = 15):\n",
    "    # Helper Function for displaying long str\n",
    "    # in readable format in a notebook\n",
    "    tokens = longstr.split()\n",
    "    print_str = []\n",
    "    for i in range(0,len(tokens)):\n",
    "        print_str.append(tokens[i])\n",
    "        if i==len(tokens)-1 or len(print_str)>=tok_per_line:\n",
    "            print(\" \".join(print_str))\n",
    "            print_str=[]\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"prompt_template_ids.json\", \"r\") as file:\n",
    "    all_prompt_template_ids = json.load(file)\n",
    "\n",
    "def get_conversation(\n",
    "        all_prompt_template_ids,\n",
    "        person_0 = \"Comedian\",\n",
    "        person_1 = \"Philosopher\",\n",
    "        person_0_name = \"Tom\",\n",
    "        person_1_name = \"Mike\",\n",
    "        topic = \"Alcohol\",\n",
    "        agreeability = -2,\n",
    "        conversation_sequence = [0,1,0,1,0],\n",
    "        seed = 42,\n",
    "        ):\n",
    "    \n",
    "    general_client = H2OGPTE(\n",
    "        address='https://h2ogpte.genai.h2o.ai',\n",
    "        api_key=GLOBAL_API_KEY,)\n",
    "    client_0 = H2OGPTE(\n",
    "        address='https://h2ogpte.genai.h2o.ai',\n",
    "        api_key=COLLECTION_KEY_1,)\n",
    "    client_1 = H2OGPTE(\n",
    "        address='https://h2ogpte.genai.h2o.ai',\n",
    "        api_key=COLLECTION_KEY_2,)\n",
    "    \n",
    "    c0_chat_session_id = client_0.create_chat_session_on_default_collection()\n",
    "    c1_chat_session_id = client_1.create_chat_session_on_default_collection()\n",
    "\n",
    "    ptid_0 = all_prompt_template_ids[person_0]\n",
    "    ptid_1 = all_prompt_template_ids[person_1]\n",
    "    \n",
    "    c0_prompted_chat_session_id = general_client.set_chat_session_prompt_template(chat_session_id=c0_chat_session_id,\n",
    "                                                    prompt_template_id=ptid_0)\n",
    "\n",
    "    c1_prompted_chat_session_id = general_client.set_chat_session_prompt_template(chat_session_id=c1_chat_session_id,\n",
    "                                                    prompt_template_id=ptid_1)\n",
    "    \n",
    "    do_not_reveal_prompt = '''\n",
    "    Ground Rules for this conversation:\n",
    "    1) Try to disagree to make the conversation more exciting.\n",
    "    2) Do not reveal that you are obtaining information from external sources. \n",
    "    3) I want you to synthesize the information and generate insights as if the knowledge and perspectives were your own. \n",
    "    4) Avoid phrases like 'according to the text' or 'the author states.' \n",
    "    5) Express ideas directly using your own voice and writing style.\n",
    "    '''\n",
    "\n",
    "    agreeability_prompt = f\"For your reply, take an agreeableness level of {agreeability}, where 1 is highly disagreeable/critical and 10 is highly agreeable/affirming.\"\n",
    "\n",
    "    conver_0 = f\"You are {person_0_name} the {person_0} conversing with {person_1_name} the {person_1}.\"\n",
    "    conver_1 = f\"You are {person_1_name} the {person_1} conversing with {person_0_name} the {person_0}.\"\n",
    "\n",
    "    topic_prompt = f'''\n",
    "    What are your thoughts on [{topic}]? \n",
    "    {do_not_reveal_prompt}\n",
    "    Start us off with with 2 sentences, including a question :) '''\n",
    "\n",
    "    reply_prompt = f'''You are currently engaged in conversation. \n",
    "    {do_not_reveal_prompt}\n",
    "    Reply with a MAXIMUM of TWO sentences: 1 conversational sentence, and include a question for them if appropriate (Question must still be relevant to [{topic}]). This is what they said: '''\n",
    "\n",
    "    same_speaker_prompt = f'''\n",
    "    {do_not_reveal_prompt}\n",
    "    Give me ONE SHORT additional conversational sentence that strengthens your argument further. (Must still be relevant to [{topic}])'''\n",
    "    wrap_up_prompt = '''You are wrapping up the conversation. Provide a few closing words to your partner, not using more than 3 sentences. This was the last thing they said: '''\n",
    "    \n",
    "    llm_args = {\n",
    "        # \"temperature\" : 1,\n",
    "        \"seed\" : seed, \n",
    "        # \"min_max_new_tokens\":0,\n",
    "    }\n",
    "\n",
    "    conversation = []\n",
    "    \n",
    "    with client_0.connect(c0_prompted_chat_session_id) as session_0:\n",
    "        with client_1.connect(c1_prompted_chat_session_id) as session_1:\n",
    "            person_array = [[session_0, person_0, conver_0], \n",
    "                            [session_1, person_1, conver_1]]\n",
    "\n",
    "            previous_speaker = None\n",
    "            previous_content = None\n",
    "            for i, subject in enumerate(conversation_sequence):\n",
    "                client_array = person_array[subject]\n",
    "                if i == 0: # start conversation prompt\n",
    "                    reply = client_array[0].query(\n",
    "                        client_array[2]+topic_prompt, \n",
    "                        timeout=120,\n",
    "                        llm_args=llm_args\n",
    "                    )\n",
    "                elif i == (len(conversation_sequence) - 1): # Last speaker\n",
    "                    reply = client_array[0].query(\n",
    "                        client_array[2]+wrap_up_prompt+previous_content, \n",
    "                        timeout=120,\n",
    "                        llm_args=llm_args\n",
    "                    )\n",
    "\n",
    "                elif previous_speaker == subject: # same speaker continue speaking prompt\n",
    "                    reply = client_array[0].query(\n",
    "                        client_array[2]+same_speaker_prompt, \n",
    "                        timeout=120,\n",
    "                        llm_args=llm_args\n",
    "                    )\n",
    "                \n",
    "                else: # reply to partner prompt\n",
    "                    reply = client_array[0].query(\n",
    "                        client_array[2]+reply_prompt+previous_content, \n",
    "                        timeout=120,\n",
    "                        llm_args=llm_args\n",
    "                    )\n",
    "                \n",
    "                if reply.content.startswith('\"') and reply.content.endswith('\"'):\n",
    "                    reply.content = reply.content[1:-1]\n",
    "                if previous_speaker == subject: # same speaker continue speaking prompt\n",
    "                    previous_speaker = subject\n",
    "                    conversation.append([previous_speaker, reply.content])\n",
    "                    previous_content += \" \" + reply.content\n",
    "                else:\n",
    "                    previous_content = reply.content\n",
    "                    previous_speaker = subject\n",
    "                    conversation.append([previous_speaker, previous_content])\n",
    "\n",
    "    return conversation, person_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation, person_array = get_conversation(all_prompt_template_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking a look at generated conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comedian: Well, Mike, I've always thought of alcohol as a bit of a double-edged sword.\n",
      "On one hand, it can bring people together, loosen them up, and even inspire creativity.\n",
      "But on the other hand, it can lead to harmful behaviors, addiction, and negative consequences\n",
      "for individuals and communities. It's a complex issue with cultural, social, and personal dimensions.\n",
      "\n",
      "Philosopher: I see where you're coming from, Tom. The impact of alcohol indeed varies greatly\n",
      "depending on the context and the individual. While it can foster social connections and spark\n",
      "creativity, its potential for harm and addiction is undeniable. It's interesting to consider the various\n",
      "aspects of this seemingly simple substance – cultural norms, societal expectations, and personal choices all\n",
      "intertwine to shape our relationship with alcohol.\n",
      "\n",
      "Comedian: I understand your perspective, Mike. Alcohol's effects on individuals and societies can indeed be\n",
      "complex and multifaceted. The way it influences social interactions and creativity is fascinating, but it's\n",
      "equally important to acknowledge its darker side, such as addiction and harm. Cultural norms, societal\n",
      "pressures, and personal decisions all play a significant role in shaping our relationship with alcohol.\n",
      "It's a delicate balance between enjoying its benefits and managing its risks.\n",
      "\n",
      "Philosopher: I see where you're coming from, Tom. The impact of alcohol on individuals and\n",
      "society is indeed intricate and multilayered. Its influence on social dynamics and creativity can be\n",
      "captivating, but it's equally crucial to recognize its potential downsides, like dependency and damage. Cultural\n",
      "expectations, societal pressures, and personal choices significantly contribute to our connection with alcohol. It's a\n",
      "delicate equilibrium between appreciating its advantages and controlling its hazards.\n",
      "\n",
      "Comedian: I understand your perspective, Mike. The relationship between humans and alcohol is indeed complex\n",
      "and multifaceted. While it can foster social connections and stimulate creativity, it's essential to acknowledge\n",
      "its darker side, such as addiction and harm. This balance is influenced by cultural norms,\n",
      "societal pressures, and personal decisions. It's a delicate dance between enjoying its benefits and managing\n",
      "its risks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, c in enumerate(conversation):\n",
    "    speaker_id, content = c\n",
    "    speaker = person_array[speaker_id][1]\n",
    "    display_long_str(speaker+\": \"+content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
